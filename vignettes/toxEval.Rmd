<!--
%\VignetteEngine{knitr::knitr}
%\VignetteIndexEntry{Introduction to toxEval}
-->

```{r setup, include=FALSE}
library(xtable)
options(continue=" ")
options(width=100)
library(knitr)
```

# Introduction to toxEval
By Laura A. De Cicco, Steven Corsi

This package **toxEval** is an early test version of the package that will encompass the various approaches to evaluate ToxCast data in relation to measured aquatic concentrations.

## Molecular weights
ToxCast reports values in $\log$$\mu$M. Data from water samples collected are typically mg/L, ng/L, or pg/L. Therefore, the first step is to determine the molecular weight of the measured data. The package **webchem** supports this functionality. 


```{r}

library("webchem")

molweight <- cir_query('3380-34-5', "mw")
molweight

```

## Workflow
Data measured in aquatic environments can come in many different formats. This package will use example data measured from passive samplers, as well as water samples taken at a variety of sites around the Great Lakes. 

### Passive Data:
Passive data was returned from the laboratory in a 'long' format. A sample of the data is shown below:

```{r echo=TRUE, eval=TRUE}

packagePath <- system.file("extdata", package="toxEval")
filePath <- file.path(packagePath, "passiveData.RData")
load(file=filePath)

head(passiveData[,1:7])

# Unique units:
unique(passiveData$Units)

```

For this data, the CAS column was used to retrieve the molecular weight (mlWt). Each column is a unique site where the data was collected. Each row is a unique measured chemical. 

Some of the data is 'left-censored'. This means that the measured data was lower than the detection limit of the measurement technique. Values that are found to be lower than the detection limit are indicated by a "<". The first thing to check is that the method quantitation limit (MQL) or minimum level of detectability (MLD) are low enough to be ignored. That is, MQL and MLD are below the minumum endpoint levels. If so, we can simply remove any values that have the "<" indicator. To begin the study of the endpoints and how they relate to our data, we need to load up the **toxEval** package, and choose an endpoint dataset. We will use the AC50gain dataset in this report.

For this workflow, we will use the units reported by the measured data, meaning we need to convert the ToxCast end points to the units in the "Units" column of the passiveData data frame (we could also do the analysis converting the measured data to $\log$$\mu$M... it shouldn't matter as long as you are consistent).

```{r message=FALSE}
library(toxEval)

# AC50 data provided in the toxEval package:
AC50gain <- AC50gain

head(AC50gain[,1:5])

```

The units in the AC50gain, AC50loss, and AC10 data sets are $\log$$\mu$M. The first step is to convert to the desired unit (`r unique(passiveData$Units)`) based on the passiveData data frame.

$$
\require{cancel}
\begin{aligned}
Reported Data = \log \mu M \\
\mu M = 10^{\log \mu M} \\
MW = \frac{g}{mol} , M = \frac{mol}{L}  \\
\cancel{\mu M} \left[\frac{\cancel{M}}{10^6 \cancel{\mu M}}\right] \left[\frac{1}{\cancel{M}}  \frac{\cancel{mol}}{L}\right] \left[ \frac{MW \cancel{g}}{\cancel{mol}}\right] \left[\frac{10^9 ng}{\cancel{g}}\right] = MW * 10^3 \frac{ng}{L} 
\end{aligned}
$$

```{r message=FALSE}
library(dplyr)

unitConversion <- setNames(c(10^6, 10^3), c("pg/L", "ng/L") )

AC50 <- left_join(AC50gain, passiveData[,c("CAS", "Units", "mlWt")],
                   by= c("casn" = "CAS")) %>%
  filter(!is.na(Units)) %>%
  rename(desiredUnits = Units) %>%
  mutate(conversion = unitConversion[desiredUnits] * mlWt) %>%
  select(casn, chnm, desiredUnits, mlWt, conversion)

```

A sample of the AC50 data frame is shown here:

```{r echo=FALSE}
kable(head(AC50), digits=2, row.names = FALSE)

```

Next we can create a data frame with the AC50 converted endpoints:
```{r}
AC50Converted <- left_join(AC50, AC50gain)
infoColumns <- c("casn", "chnm", "desiredUnits","mlWt", "conversion", "code","chid")

endPointData <- AC50Converted[,!(names(AC50Converted) %in% infoColumns)]
endPointData <- 10^endPointData
endPointData <- endPointData * AC50Converted$conversion
endPoint <- cbind(AC50, data.frame(endPointData))
endPoint <- rename(endPoint, Units=desiredUnits)

```

Now, let's look at the extreme reported endpoint (not including `r NA`'s):

```{r warning=FALSE}
maxEndPoints <- apply(endPointData, 1, max, na.rm=TRUE) 
minEndPoints <- apply(endPointData, 1, min, na.rm=TRUE)

maxMinSummary <- cbind(endPoint[,c("chnm", "casn", "Units")], 
                       maxEndPoint=maxEndPoints, 
                       minEndPoint=minEndPoints)

```

Next, let's determine if the MQL or MLD are going to tell us anything in relation to the ToxCast endpoints. Likewise, we can look at the maximum and minimum measured values.

```{r warning=FALSE}
siteColumns <- grep("site",names(passiveData))
maxMinSummary <- left_join(maxMinSummary,passiveData[,-siteColumns], 
                           by=c("casn"="CAS", "Units"="Units"))

```

If any of the MLD are higher than the maxEndPoint, we wouldn't be able to make any conclusions about the toxicity of the water:

```{r}
sum(maxMinSummary$MLD > maxMinSummary$minEndPoint)

```

So, `r sum(maxMinSummary$MLD > maxMinSummary$maxEndPoint)` measurements have detection limitations that are greater than the minimum endpoint concentration. We might be interested to know how close the detection limit values come to the minimum endpoints. 

The following chemicals have MLD's within 0.01 of the miniumum endpoint value:

```{r echo=FALSE}
dfToPrint <- mutate(maxMinSummary, MLD_EAR = MLD/minEndPoint) %>%
  filter(MLD_EAR > 0.01) %>%
  select(chnm, minEndPoint, MLD, MLD_EAR) %>%
  arrange(desc(MLD_EAR)) %>%
  rename("Maximum Ratio"=MLD_EAR)
  
kable(dfToPrint, digits=2)
```

Since it appears that we can ignore the censored values, the easist way to convert data to numbers then is to use the `as.numeric` function. This will convert the left-censored data to `NA`, generating a warning. To convert all the columns with the word 'site' in their column name to numeric, use the following commands:

```{r warning=FALSE}
siteColumns <- grep("site",names(passiveData))
passiveData[,siteColumns] <- sapply(passiveData[,siteColumns], function(x) as.numeric(x))

#For this analysis, we'll consider NA's to be 0 (other options exist):
passiveData[,siteColumns][is.na(passiveData[,siteColumns])] <- 0

```

Now let's check if the maximum measured values are greater than the minimum endpoint values:


```{r echo=FALSE}
dataSummary <- select(passiveData, CAS, Units) %>%
  mutate(maxMeasure = apply(passiveData[,siteColumns], 1, max, na.rm=TRUE)) %>%
  mutate(minMeasure = apply(passiveData[,siteColumns], 1, min, na.rm=TRUE)) 

maxMinSummaryNew <- left_join(maxMinSummary, dataSummary, 
                              by=c("casn" = "CAS", "Units"="Units")) %>%
  mutate(EAR = maxMeasure/minEndPoint) %>%
  filter(EAR > 0.01) %>%
  arrange(desc(EAR)) %>%
  select(Chemical, minEndPoint, maxMeasure, EAR) 
  

kable(maxMinSummaryNew, digits=2)


```








```{r warning=FALSE}
# sum(as.numeric(maxMinSummary$Max) > maxMinSummary$minEndPoint, na.rm = TRUE)

```

Most likely, those will be the most interested case is when at least one of the measured values is higher than the minimum endpoint value:


```{r echo=FALSE, warning=FALSE}

# maxMinSummaryNumber <- maxMinSummary
# maxMinSummaryNumber$Max <- as.numeric(maxMinSummary$Max)
# maxMinSummaryNumber <- maxMinSummaryNumber[!is.na(maxMinSummaryNumber$Max),]
# 
# kable(maxMinSummaryNumber[maxMinSummaryNumber$Max > maxMinSummaryNumber$minEndPoint,c(1:5,7:8,10:11)], 
#       digits=2, row.names = FALSE)

```

### Data Analysis


Let's start our analysis with one site (the first of the site columns: site04101500):

```{r message=FALSE}
commonColumns <- c("Chemical", "Units", 
                  "MLD", "MQL", "CAS", "mlWt")
oneSite <- passiveData[,c(commonColumns, "site04101500")]
oneSite <- rename(oneSite, value = site04101500)
head(oneSite)

```

We can now look at the ratio of the measured data to the endpoints:

```{r}
casnRow <- setNames(1:nrow(oneSite),oneSite$CAS)
ratioPassive <- oneSite[casnRow[endPoint$casn],"value"] / endPointData
maxRatio <- suppressWarnings(max(apply(ratioPassive[,siteColumns], 1, max, na.rm=TRUE) ))
  
```

So for the passive dataset, the maximum ratio of the measured data to the endpoints for all chemicals at the first site is `r maxRatio`.

Extending this to all sites:

```{r echo=TRUE, eval=TRUE, warning=FALSE}

siteColumnsIndex <- grep("site", names(passiveData))
maxRatioBySite <- data.frame(site=names(passiveData)[siteColumnsIndex],
                             ratio_perc=rep(NA, length(siteColumnsIndex)),
                             chemical = rep("", length(siteColumnsIndex)),
                             endpoint =  rep("", length(siteColumnsIndex)),
                             stringsAsFactors=FALSE)



for(i in names(passiveData)[siteColumnsIndex]){ # i = site columns
  oneSite <- passiveData[,c(commonColumns, i)]
  names(oneSite)[names(oneSite) == i] <- 'value'
  casnRow <- setNames(1:nrow(oneSite),oneSite$CAS) # casnRow gets index of CAS in oneSite
  ratioPassive <- oneSite[casnRow[endPoint$casn],"value"] / endPointData
  
  maxRatio <- max(apply(ratioPassive[,siteColumnsIndex], 1, max, na.rm=TRUE) )*100
  maxRatioBySite[maxRatioBySite$site == i,"ratio_perc"] <- maxRatio
  
  if(is.finite(maxRatio)){
    maxIndexChemical <- which.max(apply(ratioPassive[,siteColumnsIndex], 1, max, na.rm=TRUE) )
    maxIndexEndpoint <- apply(ratioPassive[,siteColumnsIndex], 1, which.max)[[maxIndexChemical]]
    maxRatioBySite[maxRatioBySite$site == i,"chemical"] <- passiveData$Chemical[maxIndexChemical]
    maxRatioBySite[maxRatioBySite$site == i,"endpoint"] <- names(endPoint)[maxIndexEndpoint]
  }
}

maxRatioBySite <- maxRatioBySite[order(maxRatioBySite$ratio_perc, decreasing = TRUE),]
names(maxRatioBySite) <- c("site", "Ratio [%]", "Chemical", "End Point")

kable(maxRatioBySite, digits=2, row.names = FALSE)

```

So for the passive dataset, the maximum ratio of the measured data to the endpoints for all chemicals at all sites is `r maxRatioBySite[1,2]`, at site `r maxRatioBySite[1,1]`, from `r maxRatioBySite[1,3]`, based on endpoint `r maxRatioBySite[1,4]`


### Water Sample Data:
The data returned from water sample tests was returned in a 'wide' format:

```{r echo=TRUE, eval=TRUE}

packagePath <- system.file("extdata", package="toxEval")
filePath <- file.path(packagePath, "waterSamples.RData")
load(file=filePath)

head(waterSamples[,1:10])

```

The first job is to once again find the unique units. This data is arranged by a 5 digit USGS parameter code. Using the **dataRetrieval** package, information about the parameter codes can be retrieved. Each parameter code has 6 columns: detectionLimit, rep_lev_cd, qualifier, valueToUse, val_qual_tex, meth_cd, dqi_cd. We can pull out one of those columns to find the unique paremeter codes, then use **webchem** to get the molecular weights.

```{r message=FALSE, eval=FALSE}
library(dataRetrieval)

waterSamplePCodes <- names(waterSamples)[grep("valueToUse", names(waterSamples))]
waterSamplePCodes <- sapply(strsplit(waterSamplePCodes, "_"), function(x) x[2])

pCodeInfo <- readNWISpCode(waterSamplePCodes)

unique(pCodeInfo$parameter_units)

library(webchem)
pCodeInfo$mlWt <- rep(NA, nrow(pCodeInfo))
pCodeInfo$mlWt[pCodeInfo$casrn != ""] <- sapply(pCodeInfo$casrn[pCodeInfo$casrn != ""],
                function(x) cir_query(x, "mw", first = TRUE))
pCodeInfo$mlWt <- as.numeric(pCodeInfo$mlWt)

```

```{r message=FALSE, echo=FALSE}
packagePath <- system.file("extdata", package="toxEval")
filePath <- file.path(packagePath, "pCodeInfo.RData")
load(file=filePath)

pCodeInfo <- pCodeInfo[pCodeInfo$casrn != "", ]

waterSamplePCodes <- names(waterSamples)[grep("valueToUse", names(waterSamples))]
waterSamplePCodes <- sapply(strsplit(waterSamplePCodes, "_"), function(x) x[2])



```

In this dataset, all the data is reported in `r unique(pCodeInfo$parameter_units)`. Our conversion therefore is:

$$
\require{cancel}
\begin{aligned}
Reported Data = \log \mu M \\
\mu M = 10^{\log \mu M} \\
MW = \frac{g}{mol} , M = \frac{mol}{L}  \\
\cancel{\mu M} \left[\frac{\cancel{M}}{\cancel{10^6} \cancel{\mu M}}\right] \left[\frac{1}{\cancel{M}}  \frac{\cancel{mol}}{L}\right] \left[ \frac{MW \cancel{g}}{\cancel{mol}}\right] \left[\frac{\cancel{10^6} \mu g}{\cancel{g}}\right] = MW * \frac{\mu g}{L} 
\end{aligned}
$$

```{r}

AC50 <- left_join(AC50gain, pCodeInfo[,c("casrn", "parameter_units", "mlWt")],
                   by= c("casn"="casrn")) %>%
  filter(!is.na(parameter_units)) %>%
  rename(desiredUnits = parameter_units) %>%
  mutate(conversion = mlWt) %>%
  select(casn, chnm, desiredUnits, mlWt, conversion)

```

Next we can create a data frame with the AC50 converted endpoints:
```{r}
AC50Converted <- left_join(AC50, AC50gain)
infoColumns <- c("casn", "chnm", "desiredUnits","mlWt", "conversion", "code","chid")

endPointData <- AC50Converted[,!(names(AC50Converted) %in% infoColumns)]
endPointData <- 10^endPointData
endPointData <- endPointData * AC50Converted$conversion
endPoint <- cbind(AC50, data.frame(endPointData))
endPoint <- rename(endPoint, Units=desiredUnits)

```

First, let's look at the extreme reported endpoint (not including `r NA`'s...that will actually be very important):

```{r warning=FALSE}
maxEndPoints <- apply(endPointData, 1, max, na.rm=TRUE) 
minEndPoints <- apply(endPointData, 1, min, na.rm=TRUE)

maxMinSummary <- cbind(endPoint[,c("chnm", "casn", "Units")], 
                       maxEndPoint=maxEndPoints, 
                       minEndPoint=minEndPoints)

```

The next task is to determine if the detectionLimit is going to tell us anything in relation to the ToxCast endpoints. Likewise, we can look at the maximum and minimum measured values.

```{r }
pCodeSummary <- select(pCodeInfo, srsname, casrn, parameter_units, mlWt)

detectionLimits <- waterSamples[,grep("detectionLimit", names(waterSamples))]
detectionLimits <- na.omit(detectionLimits)

# Check if any changes over time:
all(apply(detectionLimits, 2, function(x) length(unique(x))==1))

#It does!

```

For now, we'll focus on the minimum detection level:


